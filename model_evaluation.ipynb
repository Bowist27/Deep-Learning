{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# M√≥dulo 2 Implementaci√≥n de un modelo de deep learning\n",
        "## Docente: Benjamin\n",
        "## Jos√© Antonio L√≥pez Salda√±a A01710367\n",
        "---\n",
        "\n",
        "*Evaluaci√≥n de modelos de Deepfake 7-clases (CNN de 0 y CNN pre-creada)*"
      ],
      "metadata": {
        "id": "7PixjMi2yPQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaci√≥n de modelo Deepfake 7-clases\n",
        "\n",
        "## (Evaluaci√≥n de CNN 128 x 128)\n",
        "---\n",
        "Pipeline de inferencia para videos"
      ],
      "metadata": {
        "id": "Ot-ujjt1ydaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Si no los tienes, descomenta una vez:\n",
        "# !mkdir -p /content/models\n",
        "# !wget -q -O /content/models/deploy.prototxt https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n",
        "# !wget -q -O /content/models/res10_300x300_ssd_iter_140000.caffemodel https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"
      ],
      "metadata": {
        "id": "JK6NKzthAnj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definiciones/Configuraci√≥n del entorno de dataset**\n",
        "\n",
        "*Defino la ruta y carpetas donde est√° la informaci√≥n del modelo creado*"
      ],
      "metadata": {
        "id": "LWcr1ukE_U6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Clases EXACTAS que usaste al entrenar\n",
        "METHODS = [\n",
        "    \"original\", \"DeepFakeDetection\", \"Deepfakes\",\n",
        "    \"Face2Face\", \"FaceShifter\", \"FaceSwap\", \"NeuralTextures\"\n",
        "]\n",
        "IDX_ORIGINAL = METHODS.index(\"original\")\n",
        "\n",
        "IMG_SIZE = (128, 128)  # <-- tu modelo actual\n",
        "TH_FRAME_REALFAKE = 0.5   # umbral p_fake por frame\n",
        "TH_VIDEO_REALFAKE = 0.5   # umbral p_fake promedio por video\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLkK5tus_6wb",
        "outputId": "eb1b750b-e70d-485f-905b-1a8e54574bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.7.2 is installed, but it is not compatible with the installed jaxlib version 0.5.3, so it will not be used.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detector de rostros (OpenCV DNN)**\n",
        "\n",
        "*Detectar y recortar una sola cara de una imagen usando el detector DNN de OpenCV, devolverla como un recorte cuadrado del tama√±o (128√ó128)*"
      ],
      "metadata": {
        "id": "M-Py7OKkAR9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DNN_PROTO = \"/content/models/deploy.prototxt\"\n",
        "DNN_WEIGHTS = \"/content/models/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "\n",
        "_dnn = cv2.dnn.readNetFromCaffe(DNN_PROTO, DNN_WEIGHTS)\n",
        "\n",
        "\n",
        "def crop_one_face_bgr(img_bgr, out_size=IMG_SIZE[0], conf_thresh=0.5):\n",
        "    \"\"\"\n",
        "    Detecta y recorta UNA cara del frame usando OpenCV DNN.\n",
        "    Devuelve un recorte cuadrado BGR de tama√±o out_size x out_size.\n",
        "    \"\"\"\n",
        "    h, w = img_bgr.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(\n",
        "        cv2.resize(img_bgr, (300, 300)), 1.0, (300, 300),\n",
        "        (104.0, 177.0, 123.0), False, False\n",
        "    )\n",
        "    _dnn.setInput(blob)\n",
        "    detections = _dnn.forward()\n",
        "\n",
        "    conf = 0.0\n",
        "    if detections.shape[2] > 0:\n",
        "        i = np.argmax(detections[0, 0, :, 2])\n",
        "        conf = float(detections[0, 0, i, 2])\n",
        "\n",
        "    if conf >= conf_thresh:\n",
        "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "        x1, y1, x2, y2 = box.astype(int)\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(w, x2), min(h, y2)\n",
        "        face = img_bgr[y1:y2, x1:x2]\n",
        "        if face.size == 0:\n",
        "            s = min(h, w)\n",
        "            y = (h - s) // 2\n",
        "            x = (w - s) // 2\n",
        "            face = img_bgr[y:y+s, x:x+s]\n",
        "    else:\n",
        "        # Fallback: recorte centrado cuadrado\n",
        "        s = min(h, w)\n",
        "        y = (h - s) // 2\n",
        "        x = (w - s) // 2\n",
        "        face = img_bgr[y:y+s, x:x+s]\n",
        "\n",
        "    return cv2.resize(face, (out_size, out_size))"
      ],
      "metadata": {
        "id": "sZC8oc3x_7gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 3) CARGAR MODELO ENTRENADO\n",
        "# -------------------------------\n",
        "\n",
        "CKPT_DIR = Path(\"/content/ffpp_checkpoints_efficient\")\n",
        "\n",
        "MODEL_CANDIDATES = [\n",
        "    CKPT_DIR / \"best_model_auc.keras\",\n",
        "    CKPT_DIR / \"best_model_acc.keras\",\n",
        "]\n",
        "\n",
        "def load_trained_model():\n",
        "    \"\"\"\n",
        "    Carga el modelo guardado (.keras) de tu CNN eficiente 7 clases.\n",
        "    Usa compile=False porque solo queremos hacer predicciones.\n",
        "    \"\"\"\n",
        "    for p in MODEL_CANDIDATES:\n",
        "        if p.exists():\n",
        "            print(f\"‚úì Cargando modelo: {p}\")\n",
        "            return tf.keras.models.load_model(p, compile=False)\n",
        "    raise FileNotFoundError(\n",
        "        f\"‚ùå No encuentro ning√∫n modelo .keras en {CKPT_DIR}. \"\n",
        "        f\"Esperaba: {[str(p) for p in MODEL_CANDIDATES]}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "Q9mJB6seABTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 4) PREPROCESAMIENTO PARA LA CNN\n",
        "# -------------------------------\n",
        "\n",
        "def preprocess_face_bgr(img_bgr):\n",
        "    \"\"\"\n",
        "    Convierte BGR ‚Üí RGB y prepara el tensor para el modelo.\n",
        "\n",
        "    IMPORTANTE:\n",
        "    - Tu modelo hace `Rescaling(1./255)` adentro.\n",
        "    - Por eso aqu√≠ NO normalizamos, solo convertimos a float32 [0-255].\n",
        "    \"\"\"\n",
        "    if img_bgr is None or img_bgr.size == 0:\n",
        "        raise ValueError(\"face vac√≠o\")\n",
        "\n",
        "    if img_bgr.shape[:2] != IMG_SIZE:\n",
        "        img_bgr = cv2.resize(img_bgr, IMG_SIZE)\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    x = img_rgb.astype(np.float32)  # (128,128,3)\n",
        "    return x"
      ],
      "metadata": {
        "id": "aqKDlI4dAEMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 5) PREDICCI√ìN POR VIDEO\n",
        "# -------------------------------\n",
        "\n",
        "def predict_video(model, video_path: Path,\n",
        "                  max_frames=4,\n",
        "                  save_csv=None,\n",
        "                  conf_thresh=0.5):\n",
        "    \"\"\"\n",
        "    Extrae ~1 fps, detecta caras, predice y devuelve:\n",
        "    - video_label_rf: \"fake\" o \"real\" (basado en p_fake promedio)\n",
        "    - video_p_fake: probabilidad media de fake [0-1]\n",
        "    - video_top_method: clase 7-way m√°s probable a nivel video\n",
        "    - video_top_score: probabilidad de esa clase\n",
        "    - per_frame: lista de diccionarios con resultados por frame\n",
        "    \"\"\"\n",
        "    per_frame = []\n",
        "    count = 0\n",
        "\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(str(video_path))\n",
        "        if not cap.isOpened():\n",
        "            raise RuntimeError(f\"No puedo abrir {video_path}\")\n",
        "\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
        "        step = max(int(round(fps)), 1)  # ~1 frame por segundo\n",
        "        i = 0\n",
        "\n",
        "        print(f\"\\nüìπ Procesando video: {video_path.name}\")\n",
        "        print(f\"   FPS: {fps:.1f} | Step: {step} | Max frames: {max_frames}\")\n",
        "        print(\"   \" + \"=\"*50)\n",
        "\n",
        "        while True:\n",
        "            ok, fr = cap.read()\n",
        "            if not ok:\n",
        "                break\n",
        "\n",
        "            if i % step == 0:\n",
        "                try:\n",
        "                    # Detectar y recortar cara a 128x128 (aprox.)\n",
        "                    face128 = crop_one_face_bgr(fr, out_size=IMG_SIZE[0],\n",
        "                                                conf_thresh=conf_thresh)\n",
        "\n",
        "                    # Preprocesar\n",
        "                    x = preprocess_face_bgr(face128)\n",
        "                    x = np.expand_dims(x, 0)  # (1,128,128,3)\n",
        "\n",
        "                    # Predicci√≥n 7 clases\n",
        "                    probs = model.predict(x, verbose=0)[0]  # shape: (7,)\n",
        "                    top_idx = int(np.argmax(probs))\n",
        "                    top_method = METHODS[top_idx]\n",
        "                    top_score = float(probs[top_idx])\n",
        "\n",
        "                    # Probabilidad \"real/fake\" derivada\n",
        "                    p_real = float(probs[IDX_ORIGINAL])\n",
        "                    p_fake = float(1.0 - p_real)\n",
        "                    label_rf = \"fake\" if p_fake >= TH_FRAME_REALFAKE else \"real\"\n",
        "\n",
        "                    per_frame.append({\n",
        "                        \"frame_idx\": i,\n",
        "                        \"label\": label_rf,          # real/fake\n",
        "                        \"p_fake\": p_fake,\n",
        "                        \"p_real\": p_real,\n",
        "                        \"top_method\": top_method,   # clase 7-way m√°s probable\n",
        "                        \"top_score\": top_score,\n",
        "                        \"probs\": probs.tolist(),    # vector completo 7D\n",
        "                        \"err\": \"\"\n",
        "                    })\n",
        "\n",
        "                    print(\n",
        "                        f\"   Frame {i:4d} ‚Üí {label_rf.upper()} | \"\n",
        "                        f\"p_fake={p_fake:.3f} | \"\n",
        "                        f\"{top_method} ({top_score:.3f})\"\n",
        "                    )\n",
        "\n",
        "                    count += 1\n",
        "                    if max_frames and count >= max_frames:\n",
        "                        break\n",
        "\n",
        "                except Exception as e:\n",
        "                    per_frame.append({\n",
        "                        \"frame_idx\": i,\n",
        "                        \"label\": \"error\",\n",
        "                        \"p_fake\": np.nan,\n",
        "                        \"p_real\": np.nan,\n",
        "                        \"top_method\": \"\",\n",
        "                        \"top_score\": np.nan,\n",
        "                        \"probs\": [np.nan]*len(METHODS),\n",
        "                        \"err\": repr(e)\n",
        "                    })\n",
        "                    print(f\"   Frame {i:4d} ‚Üí ERROR: {repr(e)}\")\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "    except Exception as e:\n",
        "        per_frame.append({\n",
        "            \"frame_idx\": -1,\n",
        "            \"label\": \"error\",\n",
        "            \"p_fake\": np.nan,\n",
        "            \"p_real\": np.nan,\n",
        "            \"top_method\": \"\",\n",
        "            \"top_score\": np.nan,\n",
        "            \"probs\": [np.nan]*len(METHODS),\n",
        "            \"err\": f\"video_open/iter: {repr(e)}\"\n",
        "        })\n",
        "        print(f\"‚ùå Error abriendo video: {repr(e)}\")\n",
        "\n",
        "    # -----------------------\n",
        "    # Agregaci√≥n por video\n",
        "    # -----------------------\n",
        "    probs_valid = [\n",
        "        np.array(d[\"probs\"], dtype=np.float32)\n",
        "        for d in per_frame\n",
        "        if d[\"label\"] != \"error\"\n",
        "    ]\n",
        "\n",
        "    if len(probs_valid) > 0:\n",
        "        mean_probs = np.mean(probs_valid, axis=0)  # (7,)\n",
        "        video_top_idx = int(np.argmax(mean_probs))\n",
        "        video_top_method = METHODS[video_top_idx]\n",
        "        video_top_score = float(mean_probs[video_top_idx])\n",
        "\n",
        "        video_p_real = float(mean_probs[IDX_ORIGINAL])\n",
        "        video_p_fake = float(1.0 - video_p_real)\n",
        "        video_label_rf = (\n",
        "            \"fake\" if video_p_fake >= TH_VIDEO_REALFAKE else \"real\"\n",
        "        )\n",
        "    else:\n",
        "        video_top_method = \"\"\n",
        "        video_top_score = np.nan\n",
        "        video_p_fake = np.nan\n",
        "        video_label_rf = \"error\"\n",
        "\n",
        "    # Guardar CSV opcional\n",
        "    if save_csv:\n",
        "        pd.DataFrame(per_frame).to_csv(save_csv, index=False)\n",
        "        print(f\"   üíæ CSV guardado: {save_csv}\")\n",
        "\n",
        "    return (\n",
        "        video_label_rf,  # \"real\"/\"fake\"/\"error\"\n",
        "        video_p_fake,    # prob. media de fake\n",
        "        video_top_method,\n",
        "        video_top_score,\n",
        "        per_frame,\n",
        "    )"
      ],
      "metadata": {
        "id": "80HO-SsVAL8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 6) GENERAR VIDEO ANOTADO\n",
        "# -------------------------------\n",
        "\n",
        "def annotate_and_save_sample(video_path: Path, per_frame, out_path: Path,\n",
        "                             sample_rate=1):\n",
        "    \"\"\"\n",
        "    Genera un video demo con las predicciones superpuestas.\n",
        "    Usa:\n",
        "    - label (real/fake)\n",
        "    - p_fake\n",
        "    - top_method (clase 7-way dominante)\n",
        "    \"\"\"\n",
        "    picked = [\n",
        "        d for i, d in enumerate(per_frame)\n",
        "        if (i % sample_rate == 0) and d[\"label\"] != \"error\"\n",
        "    ]\n",
        "    idx2rec = {d[\"frame_idx\"]: d for d in picked}\n",
        "\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"No puedo abrir {video_path}\")\n",
        "\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    writer = cv2.VideoWriter(\n",
        "        str(out_path),\n",
        "        cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "        10,\n",
        "        (w, h)\n",
        "    )\n",
        "\n",
        "    i = 0\n",
        "    while True:\n",
        "        ok, fr = cap.read()\n",
        "        if not ok:\n",
        "            break\n",
        "\n",
        "        d = idx2rec.get(i)\n",
        "        if d:\n",
        "            text = (\n",
        "                f\"{d['label'].upper()} | \"\n",
        "                f\"fake={d['p_fake']:.2f} | \"\n",
        "                f\"{d['top_method']} ({d['top_score']:.2f})\"\n",
        "            )\n",
        "            color = (0, 0, 255) if d[\"label\"] == \"fake\" else (0, 255, 0)\n",
        "\n",
        "            cv2.rectangle(fr, (10, 10), (800, 80), (0, 0, 0), -1)\n",
        "            cv2.putText(\n",
        "                fr, text, (20, 60),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2, cv2.LINE_AA\n",
        "            )\n",
        "\n",
        "            writer.write(fr)\n",
        "        i += 1\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    print(f\"   üé¨ Video demo guardado: {out_path}\")\n"
      ],
      "metadata": {
        "id": "G7XP7TF0z5ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 7) EJECUCI√ìN DE EJEMPLO\n",
        "# -------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Cargar modelo\n",
        "    model = load_trained_model()\n",
        "    print(f\"Input shape del modelo: {model.input_shape}\\n\")\n",
        "\n",
        "    # Video a analizar (CAMBIA ESTA RUTA)\n",
        "    VIDEO_PATH = Path(\n",
        "        \"/content/ffpp_c23/Face2Face/003_000.mp4\"\n",
        "    )\n",
        "\n",
        "    if not VIDEO_PATH.exists():\n",
        "        print(f\"‚ùå Video no encontrado: {VIDEO_PATH}\")\n",
        "        print(\"   Actualiza VIDEO_PATH con la ruta correcta\")\n",
        "    else:\n",
        "        (\n",
        "            video_label_rf,\n",
        "            video_p_fake,\n",
        "            video_top_method,\n",
        "            video_top_score,\n",
        "            per_frame,\n",
        "        ) = predict_video(\n",
        "            model,\n",
        "            VIDEO_PATH,\n",
        "            max_frames=8,  # puedes subir o bajar este n√∫mero\n",
        "            save_csv=Path(\"/content/predicciones_video_7clases.csv\"),\n",
        "            conf_thresh=0.5\n",
        "        )\n",
        "\n",
        "        # Resultado final\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üéØ RESULTADO FINAL (VIDEO)\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"   Video:          {VIDEO_PATH.name}\")\n",
        "        print(f\"   Real/Fake:      {video_label_rf.upper()} \"\n",
        "              f\"(p_fake={video_p_fake:.3f})\")\n",
        "        print(f\"   Clase 7-way:    {video_top_method} \"\n",
        "              f\"({video_top_score:.3f})\")\n",
        "        print(f\"   Frames OK:      \"\n",
        "              f\"{len([d for d in per_frame if d['label'] != 'error'])}\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        # Generar video demo (opcional)\n",
        "        demo_path = Path(\"/content/demo_prediccion_7clases.mp4\")\n",
        "        annotate_and_save_sample(VIDEO_PATH, per_frame, demo_path, sample_rate=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CULbosW8-VyY",
        "outputId": "e1feeea0-54c3-4f01-ddb0-24ccb3f87e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Cargando modelo: /content/ffpp_checkpoints_efficient/best_model_auc.keras\n",
            "Input shape del modelo: (None, 128, 128, 3)\n",
            "\n",
            "\n",
            "üìπ Procesando video: 003_000.mp4\n",
            "   FPS: 25.0 | Step: 25 | Max frames: 8\n",
            "   ==================================================\n",
            "   Frame    0 ‚Üí FAKE | p_fake=0.957 | Face2Face (0.906)\n",
            "   Frame   25 ‚Üí FAKE | p_fake=0.980 | Face2Face (0.930)\n",
            "   Frame   50 ‚Üí FAKE | p_fake=0.939 | Face2Face (0.758)\n",
            "   Frame   75 ‚Üí FAKE | p_fake=0.992 | Face2Face (0.969)\n",
            "   Frame  100 ‚Üí FAKE | p_fake=0.947 | Face2Face (0.888)\n",
            "   Frame  125 ‚Üí FAKE | p_fake=0.974 | Face2Face (0.948)\n",
            "   Frame  150 ‚Üí FAKE | p_fake=0.972 | Face2Face (0.935)\n",
            "   Frame  175 ‚Üí FAKE | p_fake=0.941 | Face2Face (0.710)\n",
            "   üíæ CSV guardado: /content/predicciones_video_7clases.csv\n",
            "\n",
            "============================================================\n",
            "üéØ RESULTADO FINAL (VIDEO)\n",
            "============================================================\n",
            "   Video:          003_000.mp4\n",
            "   Real/Fake:      FAKE (p_fake=0.962)\n",
            "   Clase 7-way:    Face2Face (0.880)\n",
            "   Frames OK:      8\n",
            "============================================================\n",
            "\n",
            "   üé¨ Video demo guardado: /content/demo_prediccion_7clases.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaci√≥n de modelo Deepfake 7-clases\n",
        "\n",
        "## (Modelo preentrenado)\n",
        "---\n",
        "jhgshgjsdghksd"
      ],
      "metadata": {
        "id": "vM7tmiS4yfIW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d9ROf-cDyQo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2CyQbd7VzzFQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}